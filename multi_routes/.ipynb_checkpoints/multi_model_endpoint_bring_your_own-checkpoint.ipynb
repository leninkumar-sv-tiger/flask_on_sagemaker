{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Define the S3 bucket and prefix where the model artifacts that will be invokable by your multi-model endpoint will be located.\n",
    "\n",
    "Also define the IAM role that will give SageMaker access to the model artifacts and ECR image that was created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -qU awscli boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket = \"sagemaker-{}-{}\".format(region, account_id)\n",
    "prefix = \"demo-multimodel-endpoint\"\n",
    "\n",
    "role = \"arn:aws:iam::171774164293:role/service-role/AmazonSageMaker-ExecutionRole-20200608T073821\" # get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model artifacts to S3\n",
    "In this example we will use pre-trained ResNet 18 and ResNet 152 models, both trained on the ImageNet datset. First we will download the models from MXNet's model zoo, and then upload them to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from botocore.client import ClientError\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "try:\n",
    "    s3.meta.client.head_bucket(Bucket=bucket)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket, CreateBucketConfiguration={\"LocationConstraint\": region})\n",
    "\n",
    "models = {\"model.tar.gz\"}\n",
    "\n",
    "for model in models:\n",
    "    key = os.path.join(prefix, model)\n",
    "    with open(\"data/\" + model, \"rb\") as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a multi-model endpoint\n",
    "### Import models into hosting\n",
    "When creating the Model entity for multi-model endpoints, the container's `ModelDataUrl` is the S3 prefix where the model artifacts that are invokable by the endpoint are located. The rest of the S3 path will be specified when invoking the model.\n",
    "\n",
    "The `Mode` of container is specified as `MultiModel` to signify that the container will host multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-MultiModelModel2021-08-30-08-29-15\n",
      "Model data Url: https://tigermle-explorations.s3.amazonaws.com/lenin/flask_on_sagemaker/multi_model/\n",
      "Container image: 171774164293.dkr.ecr.us-east-1.amazonaws.com/sagemaker:demo-sagemaker-multimodel\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:171774164293:model/demo-multimodelmodel2021-08-30-08-29-15\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"DEMO-MultiModelModel\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "# model_url = \"https://tigermle-explorations.s3.amazonaws.com/lenin/flask_on_sagemaker/multi_model/model.tar.gz\"\n",
    "model_url = \"https://tigermle-explorations.s3.amazonaws.com/lenin/flask_on_sagemaker/multi_model/\"\n",
    "# model_url = \"https://s3-{}.amazonaws.com/{}/{}/\".format(region, bucket, prefix)\n",
    "# container = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(\n",
    "#     account_id, region, \"demo-sagemaker-multimodel\"\n",
    "# )\n",
    "container = \"171774164293.dkr.ecr.us-east-1.amazonaws.com/sagemaker:demo-sagemaker-multimodel\"\n",
    "\n",
    "print(\"Model name: \" + model_name)\n",
    "print(\"Model data Url: \" + model_url)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "container = {\"Image\": container, \"ModelDataUrl\": model_url, \"Mode\": \"MultiModel\"}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, Containers=[container]\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "Endpoint config creation works the same way it does as single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: DEMO-MultiModelEndpointConfig-2021-08-30-08-29-17\n",
      "Endpoint config Arn: arn:aws:sagemaker:us-east-1:171774164293:endpoint-config/demo-multimodelendpointconfig-2021-08-30-08-29-17\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"DEMO-MultiModelEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Endpoint config name: \" + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Similarly, endpoint creation works the same way as for single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: DEMO-MultiModelEndpoint-2021-08-30-08-29-18\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:171774164293:endpoint/demo-multimodelendpoint-2021-08-30-08-29-18\n",
      "Endpoint Status: Creating\n",
      "Waiting for DEMO-MultiModelEndpoint-2021-08-30-08-29-18 endpoint to be in service...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = \"DEMO-MultiModelEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Endpoint name: \" + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke models\n",
    "Now we invoke the models that we uploaded to S3 previously. The first invocation of a model may be slow, since behind the scenes, SageMaker is downloading the model artifacts from S3 to the instance and loading it into the container.\n",
    "\n",
    "First we will download an image of a cat as the payload to invoke the model, then call InvokeEndpoint to invoke the ResNet 18 model. The `TargetModel` field is concatenated with the S3 prefix specified in `ModelDataUrl` when creating the model, to generate the location of the model in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fname = mx.test_utils.download(\n",
    "    \"https://github.com/dmlc/web-data/blob/master/mxnet/doc/tutorials/python/predict_image/cat.jpg?raw=true\",\n",
    "    \"cat.jpg\",\n",
    ")\n",
    "\n",
    "with open(fname, \"rb\") as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "js = pd.DataFrame(\n",
    "                    [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
    "                    index=[\"row 1\", \"row 2\"],\n",
    "                    columns=[\"col 1\", \"col 2\"],\n",
    "                ).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"{\n  \"code\": 500,\n  \"type\": \"InternalServerException\",\n  \"message\": \"Failed to start workers\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/DEMO-MultiModelEndpoint-2021-08-30-08-19-50 in account 171774164293 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"{\n  \"code\": 500,\n  \"type\": \"InternalServerException\",\n  \"message\": \"Failed to start workers\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/DEMO-MultiModelEndpoint-2021-08-30-08-19-50 in account 171774164293 for more information."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"text/csv\",\n",
    "    TargetModel=\"model.tar.gz\",  # this is the rest of the S3 path where the model artifacts are located\n",
    "    Body=js,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we invoke the same ResNet 18 model a 2nd time, it is already downloaded to the instance and loaded in the container, so inference is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    TargetModel=\"resnet_18.tar.gz\",\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke another model\n",
    "Exercising the power of a multi-model endpoint, we can specify a different model (resnet_152.tar.gz) as `TargetModel` and perform inference on it using the same endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    TargetModel=\"resnet_152.tar.gz\",\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add models to the endpoint\n",
    "We can add more models to the endpoint without having to update the endpoint. Below we are adding a 3rd model, `squeezenet_v1.0`. To demonstrate hosting multiple models behind the endpoint, this model is duplicated 10 times with a slightly different name in S3. In a more realistic scenario, these could be 10 new different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.test_utils.download(\n",
    "    model_path + \"squeezenet/squeezenet_v1.0-0000.params\", None, \"data/squeezenet_v1.0\"\n",
    ")\n",
    "mx.test_utils.download(\n",
    "    model_path + \"squeezenet/squeezenet_v1.0-symbol.json\", None, \"data/squeezenet_v1.0\"\n",
    ")\n",
    "mx.test_utils.download(model_path + \"synset.txt\", None, \"data/squeezenet_v1.0\")\n",
    "\n",
    "with open(\"data/squeezenet_v1.0/squeezenet_v1.0-shapes.json\", \"w\") as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "\n",
    "with tarfile.open(\"data/squeezenet_v1.0.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"data/squeezenet_v1.0\", arcname=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/squeezenet_v1.0.tar.gz\"\n",
    "\n",
    "for x in range(0, 10):\n",
    "    s3_file_name = \"demo-subfolder/squeezenet_v1.0_{}.tar.gz\".format(x)\n",
    "    key = os.path.join(prefix, s3_file_name)\n",
    "    with open(file, \"rb\") as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)\n",
    "    models.add(s3_file_name)\n",
    "\n",
    "print(\"Number of models: {}\".format(len(models)))\n",
    "print(\"Models: {}\".format(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading the SqueezeNet models to S3, we will invoke the endpoint 100 times, randomly choosing from one of the 12 models behind the S3 prefix for each invocation, and keeping a count of the label with the highest probability on each invoke response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(int)\n",
    "\n",
    "for x in range(0, 100):\n",
    "    target_model = random.choice(tuple(models))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/x-image\",\n",
    "        TargetModel=target_model,\n",
    "        Body=payload,\n",
    "    )\n",
    "\n",
    "    results[json.loads(response[\"Body\"].read())[0]] += 1\n",
    "\n",
    "print(*results.items(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating a model\n",
    "To update a model, you would follow the same approach as above and add it as a new model. For example, if you have retrained the `resnet_18.tar.gz` model and wanted to start invoking it, you would upload the updated model artifacts behind the S3 prefix with a new name such as `resnet_18_v2.tar.gz`, and then change the `TargetModel` field to invoke `resnet_18_v2.tar.gz` instead of `resnet_18.tar.gz`. You do not want to overwrite the model artifacts in Amazon S3, because the old version of the model might still be loaded in the containers or on the storage volume of the instances on the endpoint. Invocations to the new model could then invoke the old version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Delete the hosting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
